{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "language_modelling.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyNRzyrXnwmvWXgf8ZxxGYbH",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DorothyKingsley/NLP_NextWordPredictions/blob/master/language_modelling.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4fEpHSTkIP3S",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#load data into memory\n",
        "def load_data(filename):\n",
        "    #open the file as read only\n",
        "    file = open(filename, 'r')\n",
        "    #read all text\n",
        "    text = file.read()\n",
        "    #close file\n",
        "    file.close()\n",
        "    return text"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ov5hVCYEIpbT",
        "colab_type": "code",
        "outputId": "0bce2974-2e72-49ba-ed36-6684e3aefb7a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#loading republic data\n",
        "input_filename=\"republic_clean.txt\"\n",
        "doc = load_data(input_filename)\n",
        "#sanity check\n",
        "doc[:20]"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'BOOK I. The Republic'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fz5gJMunIqOf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#cleaning data\n",
        "import string\n",
        "#cleaning document to clean tokens\n",
        "def clean_data(data):\n",
        "    #replace '\\r' with ''\n",
        "    data = data.replace('\\r',' ')\n",
        "    #replace '\\n' with ''\n",
        "    data = data.replace('\\n',' ')\n",
        "    #replace '--' with a space ' '\n",
        "    data = data.replace('--',' ')\n",
        "    #split into tokens by white space\n",
        "    tokens = data.split()\n",
        "    #remove punctuations from each token\n",
        "    #most efficient way to remove punctuation higher versions should use str.maketrans('', '', string.punctuation)\n",
        "    tokens=[w.translate(str.maketrans('', '', string.punctuation)) for w in tokens] \n",
        "    #remove non-alphabetic words\n",
        "    tokens=[word for word in tokens if word.isalpha()]\n",
        "    #make lower case\n",
        "    tokens = [word.lower() for word in tokens]\n",
        "    return tokens"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D6WMmsklI8ju",
        "colab_type": "code",
        "outputId": "5a25ea8a-12b1-40e1-cffe-ddca02df3e0f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "#clean doc\n",
        "tokens = clean_data(doc)\n",
        "print('Total tokens %d'% len(tokens))\n",
        "print('Unique tokens %d'% len(set(tokens)))\n",
        "tokens[:200]"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total tokens 210245\n",
            "Unique tokens 10270\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['book',\n",
              " 'i',\n",
              " 'the',\n",
              " 'republic',\n",
              " 'opens',\n",
              " 'with',\n",
              " 'a',\n",
              " 'truly',\n",
              " 'greek',\n",
              " 'scene',\n",
              " 'a',\n",
              " 'festival',\n",
              " 'in',\n",
              " 'honour',\n",
              " 'of',\n",
              " 'the',\n",
              " 'goddess',\n",
              " 'bendis',\n",
              " 'which',\n",
              " 'is',\n",
              " 'held',\n",
              " 'in',\n",
              " 'the',\n",
              " 'piraeus',\n",
              " 'to',\n",
              " 'this',\n",
              " 'is',\n",
              " 'added',\n",
              " 'the',\n",
              " 'promise',\n",
              " 'of',\n",
              " 'an',\n",
              " 'equestrian',\n",
              " 'torchrace',\n",
              " 'in',\n",
              " 'the',\n",
              " 'evening',\n",
              " 'the',\n",
              " 'whole',\n",
              " 'work',\n",
              " 'is',\n",
              " 'supposed',\n",
              " 'to',\n",
              " 'be',\n",
              " 'recited',\n",
              " 'by',\n",
              " 'socrates',\n",
              " 'on',\n",
              " 'the',\n",
              " 'day',\n",
              " 'after',\n",
              " 'the',\n",
              " 'festival',\n",
              " 'to',\n",
              " 'a',\n",
              " 'small',\n",
              " 'party',\n",
              " 'consisting',\n",
              " 'of',\n",
              " 'critias',\n",
              " 'timaeus',\n",
              " 'hermocrates',\n",
              " 'and',\n",
              " 'another',\n",
              " 'this',\n",
              " 'we',\n",
              " 'learn',\n",
              " 'from',\n",
              " 'the',\n",
              " 'first',\n",
              " 'words',\n",
              " 'of',\n",
              " 'the',\n",
              " 'timaeus',\n",
              " 'when',\n",
              " 'the',\n",
              " 'rhetorical',\n",
              " 'advantage',\n",
              " 'of',\n",
              " 'reciting',\n",
              " 'the',\n",
              " 'dialogue',\n",
              " 'has',\n",
              " 'been',\n",
              " 'gained',\n",
              " 'the',\n",
              " 'attention',\n",
              " 'is',\n",
              " 'not',\n",
              " 'distracted',\n",
              " 'by',\n",
              " 'any',\n",
              " 'reference',\n",
              " 'to',\n",
              " 'the',\n",
              " 'audience',\n",
              " 'nor',\n",
              " 'is',\n",
              " 'the',\n",
              " 'reader',\n",
              " 'further',\n",
              " 'reminded',\n",
              " 'of',\n",
              " 'the',\n",
              " 'extraordinary',\n",
              " 'length',\n",
              " 'of',\n",
              " 'the',\n",
              " 'narrative',\n",
              " 'of',\n",
              " 'the',\n",
              " 'numerous',\n",
              " 'company',\n",
              " 'three',\n",
              " 'only',\n",
              " 'take',\n",
              " 'any',\n",
              " 'serious',\n",
              " 'part',\n",
              " 'in',\n",
              " 'the',\n",
              " 'discussion',\n",
              " 'nor',\n",
              " 'are',\n",
              " 'we',\n",
              " 'informed',\n",
              " 'whether',\n",
              " 'in',\n",
              " 'the',\n",
              " 'evening',\n",
              " 'they',\n",
              " 'went',\n",
              " 'to',\n",
              " 'the',\n",
              " 'torchrace',\n",
              " 'or',\n",
              " 'talked',\n",
              " 'as',\n",
              " 'in',\n",
              " 'the',\n",
              " 'symposium',\n",
              " 'through',\n",
              " 'the',\n",
              " 'night',\n",
              " 'the',\n",
              " 'manner',\n",
              " 'in',\n",
              " 'which',\n",
              " 'the',\n",
              " 'conversation',\n",
              " 'has',\n",
              " 'arisen',\n",
              " 'is',\n",
              " 'described',\n",
              " 'as',\n",
              " 'follows',\n",
              " 'socrates',\n",
              " 'and',\n",
              " 'his',\n",
              " 'companion',\n",
              " 'glaucon',\n",
              " 'are',\n",
              " 'about',\n",
              " 'to',\n",
              " 'leave',\n",
              " 'the',\n",
              " 'festival',\n",
              " 'when',\n",
              " 'they',\n",
              " 'are',\n",
              " 'detained',\n",
              " 'by',\n",
              " 'a',\n",
              " 'message',\n",
              " 'from',\n",
              " 'polemarchus',\n",
              " 'who',\n",
              " 'speedily',\n",
              " 'appears',\n",
              " 'accompanied',\n",
              " 'by',\n",
              " 'adeimantus',\n",
              " 'the',\n",
              " 'brother',\n",
              " 'of',\n",
              " 'glaucon',\n",
              " 'and',\n",
              " 'with',\n",
              " 'playful',\n",
              " 'violence',\n",
              " 'compels',\n",
              " 'them',\n",
              " 'to',\n",
              " 'remain',\n",
              " 'promising',\n",
              " 'them',\n",
              " 'not',\n",
              " 'only',\n",
              " 'the',\n",
              " 'torchrace']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nyx-_4RYI__H",
        "colab_type": "code",
        "outputId": "a3c8b234-26a0-40bb-87a6-5d10df0ed346",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#split the tokens further into sequences\n",
        "length = 50 + 1 #50 words considered to build a context and predict the next word. \n",
        "#consider building another model as an extension which considers self-contained sentences using truncations and padding\n",
        "sequences = list()\n",
        "for i in range(length,len(tokens)):\n",
        "    seq = tokens[i-length:i] #in this scenario 0-50, 1-51, 2-52 and so on. Try to build another model using 0-50, 51-101 etc\n",
        "    #convert it into a line\n",
        "    line = ' '.join(seq)\n",
        "    #store them in the sequences list\n",
        "    sequences.append(line)\n",
        "print('Total sequences %d'%len(sequences))"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total sequences 210194\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4LCGoondJNWn",
        "colab_type": "code",
        "outputId": "a58b6c26-011c-4e8e-eb51-58dbc62f68f4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "len(sequences[0])"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "263"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L2G9ESirJQR1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#saving the sequences to a file for re-use\n",
        "def save_doc(lines, filename):\n",
        "    doc = '\\n'.join(lines)\n",
        "    file = open(filename, 'w')\n",
        "    file.write(doc)\n",
        "    file.close()\n",
        "output_filename='republic_sequences.txt'\n",
        "save_doc(sequences,output_filename)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Ksw6N_lJllj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Training our language model\n",
        "#We are using Neural language model\n",
        "from pickle import dump\n",
        "from numpy import array\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.layers import LSTM\n",
        "from tensorflow.keras.layers import Embedding"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v2KL15f-Kaxi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#integer encode sequences of text\n",
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(sequences)\n",
        "sequence = tokenizer.texts_to_sequences(sequences)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bywWHiY0LIHt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#vocabulary\n",
        "vocab_size = len(tokenizer.word_index)+1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uJwPJzIOLLHX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#separate into input and output\n",
        "import numpy as np\n",
        "sequence = np.asarray(sequence)\n",
        "x,y = sequence[:,:-1], sequence[:,-1]\n",
        "y = to_categorical(y, num_classes = vocab_size) #converting numerical single column data into a one-hot encoder\n",
        "seq_length = x.shape[1] #defining sequence length parameter with the number of columns"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dVa2DuKQLOqe",
        "colab_type": "code",
        "outputId": "b02c4492-54e7-4f34-9cb7-1370cb4cc054",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "print(len(x[0]))\n",
        "x.shape"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "50\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(210194, 50)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BGWQeugQLRRv",
        "colab_type": "code",
        "outputId": "03b45c35-ea58-4a0b-b73d-26c1a415c8e8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 340
        }
      },
      "source": [
        "model = Sequential()\n",
        "model.add(Embedding(vocab_size,50,input_length=seq_length))\n",
        "model.add(LSTM(100, return_sequences=True))\n",
        "model.add(LSTM(100))\n",
        "model.add(Dense(100, activation='relu'))\n",
        "model.add(Dense(vocab_size, activation='softmax'))\n",
        "print(model.summary())"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding (Embedding)        (None, 50, 50)            513550    \n",
            "_________________________________________________________________\n",
            "lstm (LSTM)                  (None, 50, 100)           60400     \n",
            "_________________________________________________________________\n",
            "lstm_1 (LSTM)                (None, 100)               80400     \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 100)               10100     \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 10271)             1037371   \n",
            "=================================================================\n",
            "Total params: 1,701,821\n",
            "Trainable params: 1,701,821\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_O9QfrLVLT4V",
        "colab_type": "code",
        "outputId": "3e2d4167-42d8-48f0-cd4e-fdcf2a8aa978",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 714
        }
      },
      "source": [
        "#compile model\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "#fit model\n",
        "model.fit(x,y,batch_size=128, epochs=20)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "1643/1643 [==============================] - 453s 275ms/step - loss: 6.1348 - accuracy: 0.0969\n",
            "Epoch 2/20\n",
            "1643/1643 [==============================] - 446s 271ms/step - loss: 5.6421 - accuracy: 0.1337\n",
            "Epoch 3/20\n",
            "1643/1643 [==============================] - 447s 272ms/step - loss: 5.4093 - accuracy: 0.1536\n",
            "Epoch 4/20\n",
            "1643/1643 [==============================] - 450s 274ms/step - loss: 5.2624 - accuracy: 0.1630\n",
            "Epoch 5/20\n",
            "1643/1643 [==============================] - 450s 274ms/step - loss: 5.1362 - accuracy: 0.1708\n",
            "Epoch 6/20\n",
            "1643/1643 [==============================] - 447s 272ms/step - loss: 5.0259 - accuracy: 0.1769\n",
            "Epoch 7/20\n",
            "1643/1643 [==============================] - 447s 272ms/step - loss: 4.9306 - accuracy: 0.1814\n",
            "Epoch 8/20\n",
            "1643/1643 [==============================] - 449s 273ms/step - loss: 4.8427 - accuracy: 0.1856\n",
            "Epoch 9/20\n",
            "1643/1643 [==============================] - 449s 274ms/step - loss: 4.7621 - accuracy: 0.1903\n",
            "Epoch 10/20\n",
            "1643/1643 [==============================] - 449s 274ms/step - loss: 4.6898 - accuracy: 0.1935\n",
            "Epoch 11/20\n",
            "1643/1643 [==============================] - 452s 275ms/step - loss: 4.6238 - accuracy: 0.1962\n",
            "Epoch 12/20\n",
            "1643/1643 [==============================] - 452s 275ms/step - loss: 4.5618 - accuracy: 0.1992\n",
            "Epoch 13/20\n",
            "1643/1643 [==============================] - 453s 275ms/step - loss: 4.5040 - accuracy: 0.2013\n",
            "Epoch 14/20\n",
            "1643/1643 [==============================] - 456s 278ms/step - loss: 4.4512 - accuracy: 0.2046\n",
            "Epoch 15/20\n",
            "1643/1643 [==============================] - 455s 277ms/step - loss: 4.4007 - accuracy: 0.2065\n",
            "Epoch 16/20\n",
            "1643/1643 [==============================] - 463s 282ms/step - loss: 4.3552 - accuracy: 0.2093\n",
            "Epoch 17/20\n",
            "1643/1643 [==============================] - 461s 280ms/step - loss: 4.3128 - accuracy: 0.2109\n",
            "Epoch 18/20\n",
            "1643/1643 [==============================] - 457s 278ms/step - loss: 4.2714 - accuracy: 0.2136\n",
            "Epoch 19/20\n",
            "1643/1643 [==============================] - 456s 278ms/step - loss: 4.2351 - accuracy: 0.2163\n",
            "Epoch 20/20\n",
            "1643/1643 [==============================] - 456s 278ms/step - loss: 4.2000 - accuracy: 0.2190\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f4df79d4080>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hyqjdmGdLXNH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#save the model to a file. This can be used later\n",
        "model.save('language_model.h5')\n",
        "dump(tokenizer,open('tokenizer.pkl','wb'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C5iqDDjupIG_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# load cleaned text sequences\n",
        "in_filename = 'republic_sequences.txt'\n",
        "doc = load_data(in_filename)\n",
        "lines = doc.split('\\n')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZNMmTCiL_0QN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "seq_length = len(lines[0].split()) - 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B43gPKBZ_4PN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        },
        "outputId": "e2e8b0dd-dd8f-4b5b-dfa6-1a05c94ef880"
      },
      "source": [
        "from random import randint\n",
        "from pickle import load\n",
        "from keras.models import load_model\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "# select a seed text\n",
        "seed_text = lines[randint(0,len(lines))]\n",
        "print(seed_text + '\\n')"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "the origin of the evil is that all men from the beginning heroes poets instructors of youth have always asserted the temporal dispensation the honours and profits of justice had we been taught in early youth the power of justice and injustice inherent in the soul and unseen by any human\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mp1Q6zwiApuO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "encoded = tokenizer.texts_to_sequences([seed_text])[0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ifcIWnIWAvUo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "outputId": "ddf5cf52-b9e2-41b4-ee18-a59a0ab050a7"
      },
      "source": [
        "# predict probabilities for each word\n",
        "yhat = model.predict_classes(encoded, verbose=0)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From <ipython-input-25-1bf75f5bc24a>:1: Sequential.predict_classes (from tensorflow.python.keras.engine.sequential) is deprecated and will be removed after 2021-01-01.\n",
            "Instructions for updating:\n",
            "Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
            "WARNING:tensorflow:Model was constructed with shape (None, 50) for input Tensor(\"embedding_input:0\", shape=(None, 50), dtype=float32), but it was called on an input with incompatible shape (None, 1).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OV4_Z2iiDT_X",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "7689281e-0e20-4d3c-a5f8-fcf5f0c2fd4c"
      },
      "source": [
        "yhat"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([3912,    6, 4808, 3912, 6152, 4808, 5834,   96, 5294, 7583, 3912,\n",
              "          1,    1, 5294,    3, 4808, 6152, 4808, 3326, 5294, 3912,  246,\n",
              "          1, 3912,    1, 3915,    1, 4808, 2013,   10, 4568, 6300, 2223,\n",
              "       7583, 2880, 6152, 3912,    1, 4808, 2013, 3915, 5294, 4772, 7583,\n",
              "       3912, 2075, 3915, 4096, 4808,   96, 3429])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2X-hpSnJA0OW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "out_word = ''\n",
        "for word, index in tokenizer.word_index.items():\n",
        "  if index == yhat.any():\n",
        "\t\t  out_word = word\n",
        "\t\t  break"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WSAH9jLcBBBq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "encoded = pad_sequences([encoded], maxlen=seq_length, truncating='pre')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BX_4s1XDBE5T",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# generate a sequence from a language model\n",
        "def generate_seq(model, tokenizer, seq_length, seed_text, n_words):\n",
        "\tresult = list()\n",
        "\tin_text = seed_text\n",
        "\t# generate a fixed number of words\n",
        "\tfor _ in range(n_words):\n",
        "\t\t# encode the text as integer\n",
        "\t\tencoded = tokenizer.texts_to_sequences([in_text])[0]\n",
        "\t\t# truncate sequences to a fixed length\n",
        "\t\tencoded = pad_sequences([encoded], maxlen=seq_length, truncating='pre')\n",
        "\t\t# predict probabilities for each word\n",
        "\t\tyhat = model.predict_classes(encoded, verbose=0)\n",
        "\t\t# map predicted word index to word\n",
        "\t\tout_word = ''\n",
        "\t\tfor word, index in tokenizer.word_index.items():\n",
        "\t\t\tif index == yhat:\n",
        "\t\t\t\tout_word = word\n",
        "\t\t\t\tbreak\n",
        "\t\t# append to input\n",
        "\t\tin_text += ' ' + out_word\n",
        "\t\tresult.append(out_word)\n",
        "\treturn ' '.join(result)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eb4aOz75BKOg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "4d80b88a-c201-4d1b-9850-84e6d7edb0ec"
      },
      "source": [
        "# generate new text\n",
        "generated = generate_seq(model, tokenizer, seq_length, seed_text, 50)\n",
        "print(generated)"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "nature be true he said and the other of the soul is the same and the other and the unjust is the best of the soul and the other of the soul in the state and the other of the soul in the state and the other of the soul\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hesd-Dm_BN-X",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}